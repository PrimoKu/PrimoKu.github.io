---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a Robotics Master's student at Johns Hopkins University. I am passionate about leveraging emerging technologies like mixed reality and digital twins to advance healthcare, particularly in interventional procedures. My work focuses on integrating computer-assisted systems to enhance surgical precision and efficiency. Currently, my research includes developing high-fidelity virtual reality system for clinical training and utilizing room-scale digital twin simulation to develop machine learning algorithms.

I am a member of the Advanced Robotics and Computationally Augmented Environments ([ARCADE](https://arcade.cs.jhu.edu)) research group, led by [Mathias Unberath](https://mathiasunberath.github.io). In 2020, I earned a B.A. in Mechatronics Engineering from the National Taiwan Normal University.

Publications
------
- **StraightTrack: Towards Mixed Reality Navigation System for Percutaneous K-wire Insertion**  
  Han Zhang, Benjamin D. Kileen, **Yu-Chun Ku**, Mathias Unberath, et al.  
  *Wiley Health Technology Letters, 2024. Special Issue: MICCAI AE-CAI 2024*  
  [Paper](https://arxiv.org/abs/2410.01143)  

  <video width="725" height="450" style="padding: 0 0 15px 0;" controls autoplay muted loop>
    <source src="/videos/straighttrack_demo.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>

  In this paper, we introduce StraightTrack, a mixed reality (MR) system developed to assist in orthopedic guiding wire placement and prevent K-wire bending in complex anatomical regions. The system incorporates a rigid access cannula with an integrated marker body to minimize bending caused by contact with soft tissue or bone. Leveraging an OST HMD with on-device optical tracking, StraightTrack provides real-time surgical guidance while addressing spatial navigation challenges and reducing entry point perception errors.

- **Evaluating the Effectiveness of Visual Guidance for Out-of-View Object Localization using Mixed Reality Head-Mounted Displays**  
  **Yu-Chun Ku**, Alejandro Martin-Gomez  
  *The 2024 IEEE International Symposium on Mixed and Augmented Reality*  
  [Paper](/files/evaluating-JND.pdf)  

  ![Evaluating JND Image](/images/evaluate-JND.png)  

  In this work, we explore how different visualization techniques for guiding attention toward objects outside a user's field of view impact responsiveness and cognitive workload in MR environments. We examine three visualization paradigms through a user study involving 24 participants. By analyzing Just Noticeable Differences (JNDs) and assessing mental load with the NASA Task Load Index, we aim to determine which technique best balances user perception and cognitive effort.